{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with data\n",
    "binfilesdir = './pyRenormalize_Lenta/'\n",
    "\n",
    "# Principle of merging is represented by a number 1-3. Short description:\n",
    "# 1: Merging of random columns\n",
    "# 2: Merging of columns with minimum Kullback-Leibler divergence\n",
    "# 3. Merging of coumns with minima local Renyi entropy\n",
    "col_rem_alg = 2\n",
    "\n",
    "# Minimal number of topics (larger of equal to 2)\n",
    "min_topics = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import struct\n",
    "import multiprocessing\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGStreamData(object):\n",
    "    def __init__(self):\n",
    "        self._fgcText = 1\n",
    "        self._fgcInt = 2\n",
    "        self._fgcFloat = 3\n",
    "        self._fgcDouble = 4\n",
    "        self._fname = ''\n",
    "        self._datafile = None\n",
    "        self._lockdatafile = multiprocessing.Lock()\n",
    "        self._columnlist = {}\n",
    "        self._colcount = 0\n",
    "        self._rowcount = 0\n",
    "        self._recsize = 0\n",
    "\n",
    "    def __del__(self):\n",
    "        self.CloseDataFile()\n",
    "\n",
    "    def ColCount(self):\n",
    "        return self._colcount\n",
    "\n",
    "    def RowCount(self):\n",
    "        return self._rowcount\n",
    "\n",
    "    def OpenDataFile(self, filename, readonly=True):\n",
    "        r = False\n",
    "        try:\n",
    "            self.CloseDataFile()\n",
    "            if readonly:\n",
    "                self._datafile = open(filename, \"rb+\")\n",
    "            else:\n",
    "                self._datafile = open(filename, \"wb\")\n",
    "            self._fname = filename\n",
    "            # Read file header\n",
    "            fgdataheader_struct = '=iii'\n",
    "            self._fgdataheader_size = struct.calcsize(fgdataheader_struct)\n",
    "            self._fgdataheader = self._datafile.read(self._fgdataheader_size)\n",
    "            self._colcount, self._rowcount, self._recsize = struct.unpack(fgdataheader_struct, self._fgdataheader)\n",
    "            if self._recsize <= 0:\n",
    "                FGStreamDataColProps_struct = '=BiI65p65p'\n",
    "                self._FGStreamDataColProps_size = struct.calcsize(FGStreamDataColProps_struct)\n",
    "                colsizes = 0\n",
    "                for i in range(self._colcount):\n",
    "                    colprops = self._datafile.read(self._FGStreamDataColProps_size)\n",
    "                    coltype, colsize, colflags, colname, colcapt = struct.unpack(FGStreamDataColProps_struct, colprops)\n",
    "                    # calculate the shifts of the column beginnings in order to speed up method GetOffset()\n",
    "                    coloffs = self._fgdataheader_size + self._FGStreamDataColProps_size * self._colcount + colsizes * self._rowcount\n",
    "                    colsizes += colsize\n",
    "                    self._columnlist[i] = [coltype, colsize, colflags, colname, colcapt, coloffs]\n",
    "            r = True\n",
    "        except Exception:\n",
    "            r = False\n",
    "            self.CloseDataFile()\n",
    "        return r\n",
    "\n",
    "    def CloseDataFile(self):\n",
    "        r = False\n",
    "        if self._datafile != None:\n",
    "            try:\n",
    "                self._lockdatafile.acquire()\n",
    "                self._datafile.close()\n",
    "                r = True\n",
    "            finally:\n",
    "                self._fname = ''\n",
    "                self._datafile = None\n",
    "                self._columnlist = {}\n",
    "                self._lockdatafile.release()\n",
    "                self._colcount = 0\n",
    "                self._rowcount = 0\n",
    "                self._recsize = 0\n",
    "        return r\n",
    "\n",
    "    def GetOffset(self, ACol, ARow):\n",
    "        r = -1\n",
    "        if not ((ACol >= 0) and (ACol < self._colcount) and (ARow >= 0) and (ARow < self._rowcount)): return r\n",
    "        if self._recsize > 0:\n",
    "            r = self._fgdataheader_size + self._recsize * (ACol * self._rowcount + ARow)\n",
    "        else:\n",
    "            if self._recsize == 0:\n",
    "                # хранение данных по столбцам (старый вариант)\n",
    "                # colsizes = 0\n",
    "                # for i in range(ACol):\n",
    "                #     colsizes += self._columnlist[i][1]  # colsize\n",
    "                # r1 = self._fgdataheader_size + self._FGStreamDataColProps_size * self._colcount + colsizes * self._rowcount\n",
    "                # r1 += ARow * self._columnlist[ACol][1]  # ColSize\n",
    "                r = self._columnlist[ACol][5] + ARow * self._columnlist[ACol][1]\n",
    "            else:\n",
    "                 #data storage in rows\n",
    "                colsizes = 0\n",
    "                for colprops in self._columnlist:\n",
    "                    colsizes += colprops[1]  # colsize\n",
    "                r = self._fgdataheader_size + self._FGStreamDataColProps_size * self._colcount + colsizes * ARow\n",
    "                colsizes = 0\n",
    "                for i in range(ACol):\n",
    "                    colsizes += self._columnlist[i][1]  # colsize\n",
    "                r += colsizes\n",
    "        return r\n",
    "\n",
    "    def GetColumnAsInt(self, ACol):  # var data: TIntColumn\n",
    "        r = []\n",
    "        try:\n",
    "            self._lockdatafile.acquire()\n",
    "            offs = self.GetOffset(ACol, 0)\n",
    "            if offs < 0: raise Exception\n",
    "            #check that the data type in the column and the data being recorded match\n",
    "            if (self._recsize > 0) or (self._columnlist[ACol][0] != self._fgcInt): raise Exception\n",
    "            if self._recsize == 0:\n",
    "                self._datafile.seek(offs, 0)\n",
    "                r = list(struct.unpack(str(self._rowcount) + 'i', self._datafile.read(self._rowcount * 4)))\n",
    "            else:\n",
    "                colsizes = 0\n",
    "                for colprops in self._columnlist:\n",
    "                    colsizes += colprops[1]  # colsize\n",
    "                for i in range(self._rowcount):\n",
    "                    self._datafile.seek(offs, 0)\n",
    "                    offs += colsizes\n",
    "                    r.append(struct.unpack('i', self._datafile.read(4)))\n",
    "        except Exception:\n",
    "            r = []\n",
    "        finally:\n",
    "            self._lockdatafile.release()\n",
    "        return r\n",
    "\n",
    "    def GetColumnAsFloat(self, ACol):  # var data: TIntColumn\n",
    "        r = []\n",
    "        try:\n",
    "            self._lockdatafile.acquire()\n",
    "            offs = self.GetOffset(ACol, 0)\n",
    "            if offs < 0: raise Exception\n",
    "            #check that the data type in the column and the data being recorded match\n",
    "            if (self._recsize > 0) or (self._columnlist[ACol][0] != self._fgcFloat): raise Exception\n",
    "            if self._recsize == 0:\n",
    "                self._datafile.seek(offs, 0)\n",
    "                r = list(struct.unpack(str(self._rowcount) + 'f', self._datafile.read(self._rowcount * 4)))\n",
    "            else:\n",
    "                colsizes = 0\n",
    "                for colprops in self._columnlist:\n",
    "                    colsizes += colprops[1]  # colsize\n",
    "                for i in range(self._rowcount):\n",
    "                    self._datafile.seek(offs, 0)\n",
    "                    offs += colsizes\n",
    "                    fv, = struct.unpack('f', self._datafile.read(4))\n",
    "                    r.append(fv)\n",
    "        except Exception:\n",
    "            r = []\n",
    "        finally:\n",
    "            self._lockdatafile.release()\n",
    "        return r\n",
    "\n",
    "    def GetColumnAsText(self, ACol):  # var data: TIntColumn\n",
    "        r = []\n",
    "        try:\n",
    "            self._lockdatafile.acquire()\n",
    "            offs = self.GetOffset(ACol, 0)\n",
    "            if offs < 0: raise Exception\n",
    "            #check that the data type in the column and the data being recorded match\n",
    "            if (self._recsize > 0) or (self._columnlist[ACol][0] != self._fgcText): raise Exception\n",
    "            delNull = re.compile(\"\\x00\")\n",
    "            if self._recsize == 0:\n",
    "                self._datafile.seek(offs, 0)\n",
    "                for rn in range(self._rowcount):\n",
    "                    w, = struct.unpack('=' + str(self._columnlist[ACol][1]) + 's',\n",
    "                                       self._datafile.read(self._columnlist[ACol][1]))\n",
    "                    w = w.decode('cp1251')\n",
    "                    #delete symbols with code 0\n",
    "                    w = delNull.sub('', w)\n",
    "                    r.append(w)\n",
    "            else:\n",
    "                colsizes = 0\n",
    "                for colprops in self._columnlist:\n",
    "                    colsizes += colprops[1]  # colsize\n",
    "                for i in range(self._rowcount):\n",
    "                    self._datafile.seek(offs, 0)\n",
    "                    offs += colsizes\n",
    "                    w, = struct.unpack('=' + str(self._columnlist[ACol][1]) + 's',\n",
    "                                       self._datafile.read(self._columnlist[ACol][1]))\n",
    "                    w = w.decode('cp1251')\n",
    "                    #delete symbols with code 0\n",
    "                    w = delNull.sub('', w)\n",
    "                    r.append(w)\n",
    "        except Exception:\n",
    "            r = []\n",
    "        finally:\n",
    "            self._lockdatafile.release()\n",
    "        return r\n",
    "\n",
    "    def GetDataAsFloat(self, ACol, ARow):\n",
    "        r = 0\n",
    "        try:\n",
    "            # self._lockdatafile.acquire()\n",
    "            offs = self.GetOffset(ACol, ARow)\n",
    "            if offs < 0: raise Exception\n",
    "            # #check that the data type in the column and the data being recorded match\n",
    "            # if (self._recsize > 0) or (self._columnlist[ACol][0] != self._fgcFloat): raise Exception\n",
    "            self._datafile.seek(offs, 0)\n",
    "            r, = struct.unpack('f', self._datafile.read(4))\n",
    "        except Exception:\n",
    "            r = 0\n",
    "            # finally:\n",
    "            # self._lockdatafile.release()\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of matrix Phi\n",
    "def CalcPhiMatrix(nw, nwsum, beta):\n",
    "\n",
    "    V, K = nw.shape\n",
    "    phi = np.arange(V * K, dtype=np.float).reshape(K, V)\n",
    "    phi = ((nw + beta) / (nwsum + V * beta)).T\n",
    "    return phi\n",
    "\n",
    "#1. Returns two random indexes of columns for merging\n",
    "def GetIndexesRandom(topics):\n",
    "    k1 = random.randint(0, topics-1)\n",
    "    k2 = k1\n",
    "    while k2 == k1:\n",
    "        k2 = random.randint(0, topics-1)\n",
    "    #k1=1\n",
    "    #k2=2\n",
    "    return k1, k2\n",
    "\n",
    "# 2. Seraching for the minimum Kullback-Leibler divergence between topic pairs and deremining their indexes\n",
    "def GetIndexesKLBMin(phi):\n",
    "    \n",
    "    K, V = phi.shape\n",
    "    Klbs = []\n",
    "  \n",
    "    c1 = np.triu_indices(K)[0]\n",
    "    c2 = np.triu_indices(K)[1] + 1\n",
    "    c1 = c1[c2 != K]\n",
    "    c2 = c2[c2 != K]\n",
    "    Klb = (phi[c1] * np.log(phi[c1] / phi[c2]) + phi[c2] * np.log(phi[c2] / phi[c1])).sum(axis=1)\n",
    "    Klbs = np.column_stack((Klb, c1, c2))\n",
    "    Klbs_sorted = Klbs[np.argsort(Klbs[:, 0])]\n",
    "    \n",
    "    return int(Klbs_sorted[0, 1]), int(Klbs_sorted[0, 2])\n",
    "\n",
    "# 3. Searching for the two minima of local Renyi entropy and determining the indexes of corresponding topics\n",
    "def GetIndexesRenyiMin(phi):\n",
    "    K, V = phi.shape\n",
    "    thrsld = 1 / V    \n",
    "\n",
    "    sumprob = phi[(phi > thrsld)].sum(axis=1) / K\n",
    "    word_ratio = (phi > thrsld).sum(axis=1)\n",
    "    \n",
    "    energy = -np.log(sumprob)\n",
    "    #Gibbs-Shannon entropy:\n",
    "    word_ratio = word_ratio/(V * K)\n",
    "    entropy_gs = np.log(word_ratio)  \n",
    "     # free energy:\n",
    "    free_energy = energy - topics * entropy_gs\n",
    "    # Renyi entropy:\n",
    "    entropy_Renyi = free_energy / (topics - 1)\n",
    "    Renyis = np.column_stack((entropy_Renyi, np.arange(K)))\n",
    "    Renyis_sorted = Renyis[np.argsort(Renyis[:, 0])[::-1]]\n",
    "\n",
    "    return tuple(Renyis_sorted[0].tolist()) #Renyis_sorted[0][1], Renyis_sorted[1][1]\n",
    "\n",
    "#Recalculation of all quantities based on Phi matrix\n",
    "def CalcAllParameters(phi):\n",
    "    K, V = phi.shape\n",
    "    thrsld = 1.0 / V\n",
    "    sumprob = phi[phi > thrsld].sum()\n",
    "    word_ratio = (phi > thrsld).sum()\n",
    "\n",
    "    sumprob = sumprob / K\n",
    "    word_ratio = word_ratio / (V * K)\n",
    "    energy = -math.log(sumprob)\n",
    "    #Gibbs-Shannon entropy:\n",
    "    entropy_gs = math.log(word_ratio)  \n",
    "    # free energy:\n",
    "    free_energy = energy - K * entropy_gs\n",
    "    # Renyi entropy:\n",
    "    entropy_Renyi = free_energy / (K - 1)\n",
    "    return word_ratio, sumprob, energy, entropy_gs, free_energy, entropy_Renyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renormalize Gibbs binary output data (NW and NWSUM)\n",
      "Columns remove method: 2\n",
      "Minimum topics count: 2\n",
      "Found File Pairs:  1\n",
      "Input Files: \n",
      "     ./pyRenormalize//20topicsnews_full_nw_100_a0,100_b0,100.bin\n",
      "     ./pyRenormalize//20topicsnews_full_nwsum_100_a0,100_b0,100.bin\n",
      "     Start topics count:  100\n",
      "     Words count:  50948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ea69ffb41d4340a6ca17611282ecf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=98), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Renormalize Gibbs binary output data (NW and NWSUM)')\n",
    "random.seed()\n",
    "\n",
    "# input parameter analysis\n",
    "if col_rem_alg == 0:\n",
    "    col_rem_alg = int(input('1. Enter columns remove method (1, 2 or 3): '))\n",
    "else:\n",
    "    print('Columns remove method:', col_rem_alg)\n",
    "if min_topics == 0:\n",
    "    min_topics = int(input('2. Enter minimum topics count (>=2): '))\n",
    "    if min_topics < 2:\n",
    "        min_topics = 2\n",
    "else:\n",
    "    if min_topics < 2:\n",
    "        min_topics = 2\n",
    "    print('Minimum topics count:', min_topics)\n",
    "#\n",
    "nw_nwsum_files = []\n",
    "# searching files\n",
    "allfiles = os.listdir(binfilesdir)\n",
    "binfiles = list(filter(lambda x: x.endswith('.bin'), allfiles))\n",
    "for fn in binfiles:\n",
    "    ia = fn.rfind('_a')\n",
    "    if ia < 0:\n",
    "        continue\n",
    "\n",
    "    alpha_s = fn[ia + 2:ia + 2 + 5]\n",
    "    ib = fn.rfind('_b')\n",
    "\n",
    "    if ib < 0:\n",
    "        continue\n",
    "\n",
    "    beta_s = fn[ib + 2:ib + 2 + 5]\n",
    "    it = fn.rfind('_nw_')\n",
    "    if it >= 0:\n",
    "        topics_s = fn[it + 4:it + 4 + 3]\n",
    "        k = topics_s.rfind('_')\n",
    "        if k > 0:\n",
    "            topics_s = topics_s[0:k]\n",
    "        ff = 0\n",
    "        for fn2 in range(len(nw_nwsum_files)):\n",
    "            if nw_nwsum_files[fn2][2] == topics_s and nw_nwsum_files[fn2][3] == alpha_s and nw_nwsum_files[fn2][4] == beta_s:\n",
    "                nw_nwsum_files[fn2][0] = binfilesdir + '/' + fn\n",
    "                ff = 1\n",
    "                break\n",
    "        if ff == 0:\n",
    "            nw_nwsum_files.append(\n",
    "                [binfilesdir + '/' + fn, '', topics_s, alpha_s, beta_s])\n",
    "    it = fn.rfind('_nwsum_')\n",
    "    if it >= 0:\n",
    "        topics_s = fn[it + 7:it + 7 + 3]\n",
    "        k = topics_s.rfind('_')\n",
    "        if k > 0:\n",
    "            topics_s = topics_s[0:k]\n",
    "        ff = 0\n",
    "        for fn2 in range(len(nw_nwsum_files)):\n",
    "            if nw_nwsum_files[fn2][2] == topics_s and nw_nwsum_files[fn2][3] == alpha_s and nw_nwsum_files[fn2][4] == beta_s:\n",
    "                nw_nwsum_files[fn2][1] = binfilesdir + '/' + fn\n",
    "                ff = 1\n",
    "                break\n",
    "        if ff == 0:\n",
    "            nw_nwsum_files.append(\n",
    "                ['', binfilesdir + '/' + fn, topics_s, alpha_s, beta_s])\n",
    "# files are found and grouped in pairs\n",
    "print('Found File Pairs: ', len(nw_nwsum_files))\n",
    "# load data from files and run renormalization\n",
    "delComa = re.compile(\",\")\n",
    "delPoint = re.compile(r\"\\.\")\n",
    "\n",
    "for fpair in nw_nwsum_files:\n",
    "    progress = 0\n",
    "    fn_nw = fpair[0]\n",
    "    fn_nwsum = fpair[1]\n",
    "    vals = fpair[3]\n",
    "    vals = delComa.sub('.', vals)\n",
    "    fn_alpha = float(vals)\n",
    "    vals = fpair[4]\n",
    "    vals = delComa.sub('.', vals)\n",
    "    fn_beta = float(vals)\n",
    "    print('Input Files: ')\n",
    "    print('    ', fn_nw)\n",
    "    print('    ', fn_nwsum)\n",
    "    binfile_nw = CFGStreamData()\n",
    "    binfile_nw.OpenDataFile(fn_nw)\n",
    "    binfile_nwsum = CFGStreamData()\n",
    "    binfile_nwsum.OpenDataFile(fn_nwsum)\n",
    "    topics = binfile_nw.ColCount()\n",
    "    words = binfile_nw.RowCount()\n",
    "    # column (topic) match check\n",
    "    if topics != binfile_nwsum.ColCount():\n",
    "        print('    Warning! Files ', fn_nw, 'and', fn_nwsum,\n",
    "              'have different columns (i.e. topics) count. Missing.')\n",
    "        continue\n",
    "    print('     Start topics count: ', topics)\n",
    "    print('     Words count: ', words)\n",
    "    # create arrays and read data from files\n",
    "    \n",
    "    nw = np.arange(words * topics, dtype=np.int).reshape(words, topics)\n",
    "    nwsum = np.arange(topics, dtype=np.int)\n",
    "    \n",
    "    for k in range(topics):\n",
    "        d = binfile_nw.GetColumnAsInt(k)\n",
    "        nw[:, k] = d\n",
    "    for k in range(topics):\n",
    "        d = binfile_nwsum.GetColumnAsInt(k)\n",
    "        nwsum[k] = d[0]\n",
    "    del binfile_nw\n",
    "    del binfile_nwsum\n",
    "\n",
    "    #data is loaded into arrays\n",
    "    # create an output file\n",
    "    nwi = fn_nw.rfind('_nw_')\n",
    "    ai = fn_nw.rfind('_a')\n",
    "    outcsvfn = fn_nw[0:nwi] + \\\n",
    "        fn_nw[ai:len(fn_nw) - 4] + '_rm' + str(col_rem_alg) + '.csv'\n",
    "    ugof = open(outcsvfn, 'w', newline='')  # , encoding='utf_8_sig')\n",
    "    # , quoting=csv.QUOTE_ALL, doublequote=True, quotechar='\"')\n",
    "    writer = csv.writer(ugof, delimiter=';')\n",
    "    writer.writerow(['Topics',\n",
    "                     'Alpha',\n",
    "                     'Beta',\n",
    "                     'Word Ratio',\n",
    "                     'Sumprob',\n",
    "                     'Energy',\n",
    "                     'Shannon Entropy',\n",
    "                     'Free Energy',\n",
    "                     'Renyi Entropy'])\n",
    "\n",
    "    #calculate quantities for the initial number of topics (for the original topic solution)\n",
    "    phi = CalcPhiMatrix(nw, nwsum, fn_beta)\n",
    "    word_ratio, sumprob, energy, entropy_gs, free_energy, entropy_Renyi = CalcAllParameters(\n",
    "        phi)\n",
    "    curr_topics = topics\n",
    "    #write data in the the output csv file \n",
    "    writer.writerow(\n",
    "        [\n",
    "            curr_topics, delPoint.sub(\n",
    "                ',', str(fn_alpha)), delPoint.sub(\n",
    "                ',', str(fn_beta)), delPoint.sub(\n",
    "                    ',', str(word_ratio)), delPoint.sub(\n",
    "                        ',', str(sumprob)), delPoint.sub(\n",
    "                            ',', str(energy)), delPoint.sub(\n",
    "                                ',', str(entropy_gs)), delPoint.sub(\n",
    "                                    ',', str(free_energy)), delPoint.sub(\n",
    "                                        ',', str(entropy_Renyi))])\n",
    "\n",
    "    #delete columns in a cycle (one per iteration) and recalculate all quantities\n",
    "    if min_topics >= topics:\n",
    "        continue\n",
    "\n",
    "    for k in tqdm.tnrange(topics - min_topics):\n",
    "\n",
    "        k1 = 0\n",
    "        k2 = 0\n",
    "\n",
    "        if col_rem_alg == 1:\n",
    "            V, K = nw.shape\n",
    "            k1, k2 = GetIndexesRandom(K)\n",
    "        \n",
    "        if col_rem_alg == 2:\n",
    "            phi = CalcPhiMatrix(nw,\n",
    "                                nwsum,\n",
    "                                fn_beta)\n",
    "\n",
    "            k1, k2 = GetIndexesKLBMin(phi)\n",
    "            \n",
    "        if col_rem_alg == 3:\n",
    "            phi = CalcPhiMatrix(nw,\n",
    "                                nwsum,\n",
    "                                fn_beta)\n",
    "            \n",
    "            k1, k2 = GetIndexesRenyiMin(phi)\n",
    "\n",
    "        #merging data from columns k1 и k2 from nw array\n",
    "        nw[:, k1] += nw[:, k2]\n",
    "        #merging elements of  k1 и k2 from nwsum array\n",
    "        nwsum[k1] = nwsum[k1] + nwsum[k2]\n",
    "        #remove column k2 from nw\n",
    "        nw = np.delete(nw, k2, 1)\n",
    "        #remove element k2 from nwsum\n",
    "        nwsum = np.delete(nwsum, k2)\n",
    "        \n",
    "        #recalculation of matrix Phi\n",
    "        phi = CalcPhiMatrix(nw, nwsum, fn_beta)\n",
    "        \n",
    "        #recalculation of all quantities:\n",
    "        word_ratio, sumprob, energy, entropy_gs, free_energy, entropy_Renyi = CalcAllParameters(phi)\n",
    "        \n",
    "        #write data in the output csv file\n",
    "        curr_topics = curr_topics - 1\n",
    "        writer.writerow(\n",
    "            [\n",
    "                curr_topics, delPoint.sub(\n",
    "                    ',', str(fn_alpha)), delPoint.sub(\n",
    "                    ',', str(fn_beta)), delPoint.sub(\n",
    "                    ',', str(word_ratio)), delPoint.sub(\n",
    "                        ',', str(sumprob)), delPoint.sub(\n",
    "                            ',', str(energy)), delPoint.sub(\n",
    "                                ',', str(entropy_gs)), delPoint.sub(\n",
    "                                    ',', str(free_energy)), delPoint.sub(\n",
    "                                        ',', str(entropy_Renyi))])\n",
    "\n",
    "    # Close output file\n",
    "    ugof.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
